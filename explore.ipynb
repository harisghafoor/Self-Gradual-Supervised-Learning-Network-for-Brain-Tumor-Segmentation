{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from dataset import ThyroidNodules\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "from trainer import Trainer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    jaccard_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from eval import compute_loss,DiceLoss\n",
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size and image dimensions\n",
    "BATCH_SIZE = 16\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "\n",
    "# Hyperparameters\n",
    "H = HEIGHT\n",
    "W = WIDTH\n",
    "DEFAULT_LR = 0.001\n",
    "\n",
    "train_x= sorted(glob(os.path.join(\"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/trainval-image\",'*')))\n",
    "train_y= sorted(glob(os.path.join(\"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/trainval-mask\",'*')))\n",
    "\n",
    "valid_x= sorted(glob(os.path.join(\"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/test-image\",'*')))\n",
    "valid_y= sorted(glob(os.path.join(\"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/test-mask\",'*')))\n",
    "\n",
    "# valid_x = \"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/test-image\"\n",
    "# valid_y = \"/Users/eloise-em/Documents/Haris Ghafoor Archive/Research and Development/RnD/Thyroid Dataset/tn3k/test-mask\"\n",
    "# Create datasets and dataloaders for this fold\n",
    "train_dataset = ThyroidNodules(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    image_size=(H, W),\n",
    ")\n",
    "\n",
    "valid_dataset = ThyroidNodules(\n",
    "    valid_x,\n",
    "    valid_y,\n",
    "    image_size=(H, W),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    ")\n",
    "# device = torch.device(args.device)\n",
    "# print(\"Device:\", device)\n",
    "\n",
    "# model = AttentionUNetppGradual()\n",
    "# model = model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, \"min\", patience=10, verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, threshold):\n",
    "    # Ground truth\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > threshold\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > threshold\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([32, 1, 128, 128])\n",
      "target torch.Size([32, 1, 128, 128])\n",
      "loss tensor(1.6175, device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(seed=7)\n",
    "input = next(iter(trainer.train_loader))[0].to(trainer.device)\n",
    "output = trainer.model(input)\n",
    "target = next(iter(trainer.train_loader))[1].to(trainer.device)\n",
    "loss = compute_loss(output, target)\n",
    "print(\"output\", output.shape)\n",
    "print(\"target\", target.shape)\n",
    "print(\"loss\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4917, 5894, 9648, 9318, 7891])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(26)\n",
    "seeds = rng.randint(10000, size=5)\n",
    "seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(seed=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/11], Training Loss: 1.503756, Time (this epoch): 194.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Unet(\n",
       "   (MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (Conv1): ConvBlock(\n",
       "     (conv): Sequential(\n",
       "       (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (Conv2): ConvBlock(\n",
       "     (conv): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (Conv5): ConvBlock(\n",
       "     (conv): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (Up2): UpConv(\n",
       "     (up_medium): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "     (up): Sequential(\n",
       "       (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "       (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (3): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (UpConv2): ConvBlock(\n",
       "     (conv): Sequential(\n",
       "       (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (Up1): UpConv(\n",
       "     (up_medium): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "     (up): Sequential(\n",
       "       (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "       (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (3): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (UpConv1): ConvBlock(\n",
       "     (conv): Sequential(\n",
       "       (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       " ),\n",
       " [1.5064490940835742,\n",
       "  1.5037439160876804,\n",
       "  1.503760384188758,\n",
       "  1.503757393360138,\n",
       "  1.5037585934003195,\n",
       "  1.5037523799472385,\n",
       "  1.5037422312630548,\n",
       "  1.5037550886472066,\n",
       "  1.5037513746155633,\n",
       "  1.5037561111980013,\n",
       "  1.5037551919619243])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
