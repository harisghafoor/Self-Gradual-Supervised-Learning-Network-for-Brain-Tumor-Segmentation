{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tf\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainer import trainer\n",
    "from model import convnet\n",
    "from dataset import mnist\n",
    "from config import Config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harisghafoor/anaconda3/envs/cv_seg/lib/python3.11/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "cnn_model = trainer(model=convnet(batch_size=100,\n",
    "                                  std=0.5),\n",
    "                    seed=Config.seeds[0],dataset = mnist,configs = Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,idx = cnn_model.prepare_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([2.1849])\n",
      "tensor([0.])\n",
      "tensor([0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (0) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RnD/self_sup_seg/temporal-ensembling/trainer.py:186\u001b[0m, in \u001b[0;36mtrainer.fit\u001b[0;34m(self, train_loader, test_loader, k, alpha, lr, beta2, num_epochs, batch_size, drop, std, fm1, fm2, divide_by_bs, w_norm, data_norm, early_stop, c, n_classes, max_epochs, max_val, ramp_up_mult, n_samples, print_res, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(ntrain, n_classes)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# current outputs\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 186\u001b[0m     outputs, Z, z, l, supl, unsupl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iteration_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     acc_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration_test(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# handle metrics, losses, etc.\u001b[39;00m\n",
      "File \u001b[0;32m~/RnD/self_sup_seg/temporal-ensembling/trainer.py:96\u001b[0m, in \u001b[0;36mtrainer._iteration_train\u001b[0;34m(self, model, epoch, optimizer, outputs, z)\u001b[0m\n\u001b[1;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     93\u001b[0m zcomp \u001b[38;5;241m=\u001b[39m Variable(\n\u001b[1;32m     94\u001b[0m     z[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 96\u001b[0m loss, suploss, unsuploss, nbsup \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# save outputs and losses\u001b[39;00m\n\u001b[1;32m     99\u001b[0m outputs[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/RnD/self_sup_seg/temporal-ensembling/loss.py:31\u001b[0m, in \u001b[0;36mtemporal_loss\u001b[0;34m(out1, out2, w, labels)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtemporal_loss\u001b[39m(out1, out2, w, labels):\n\u001b[1;32m     30\u001b[0m     sup_loss, nbsup \u001b[38;5;241m=\u001b[39m masked_crossentropy(out1, labels)\n\u001b[0;32m---> 31\u001b[0m     unsup_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sup_loss \u001b[38;5;241m+\u001b[39m w \u001b[38;5;241m*\u001b[39m unsup_loss, sup_loss, unsup_loss, nbsup\n",
      "File \u001b[0;32m~/RnD/self_sup_seg/temporal-ensembling/loss.py:11\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(out1, out2)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse_loss\u001b[39m(out1, out2):\n\u001b[0;32m---> 11\u001b[0m     quad_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quad_diff \u001b[38;5;241m/\u001b[39m out1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnelement()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (0) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(train_loader= train_loader,\n",
    "              test_loader=test_loader,\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
